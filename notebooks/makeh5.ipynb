{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import sys\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import tqdm\n",
    "import h5py\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(path):\n",
    "    return [path+i for i in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets  makeh5.ipynb\tstorage\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_path = \"./storage/inpainting-dataset/validation/\"\n",
    "train_data_path = \"./storage/inpainting-dataset/512/\"\n",
    "train_mask_path = \"./storage/inpainting-dataset/mask/train_mask/\"\n",
    "validation_mask_path = \"./storage/inpainting-dataset/mask/test_mask/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_files = get_path(validation_data_path)\n",
    "train_mask_files = get_path(train_mask_path)\n",
    "validation_mask_files = get_path(validation_mask_path)\n",
    "# train_files = get_path(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = 'openimagesV4.h5'\n",
    "mask_filename = \"masks.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train_mask = len(train_mask_files)\n",
    "len_validation_mask = len(validation_mask_files)\n",
    "with h5py.File(mask_filename, \"w\") as out:\n",
    "    out.create_dataset(\"train\",(len_train_mask,256,256,3),dtype='u1') \n",
    "    out.create_dataset(\"validation\",(len_validation_mask,256,256,3),dtype='u1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dimension = 256\n",
    "with h5py.File(mask_filename, \"a\") as out:\n",
    "    for i,path in tqdm.tqdm(enumerate(train_mask_files)):\n",
    "        img = Image.open(path).convert(\"RGB\").resize((dimension, dimension))\n",
    "        out[\"train\"][i,...] = np.asarray(img)\n",
    "    for i, path in tqdm.tqdm(enumerate(validation_mask_files)):\n",
    "        img = Image.open(path).convert(\"RGB\").resize((dimension, dimension))\n",
    "        out[\"validation\"][i,...] = np.asarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train_mask = len(train_mask_files)\n",
    "len_validation_mask = len(validation_data_files)\n",
    "with h5py.File(mask_filename, \"w\") as out:\n",
    "    out.create_dataset(\"train\",(len_train_mask,256,256,3),dtype='u1') \n",
    "    out.create_dataset(\"validation\",(len_validation_mask,256,256,3),dtype='u1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dimension = 256\n",
    "with h5py.File(data_filename, \"a\") as out:\n",
    "    for i,path in tqdm.tqdm(enumerate(train_data_files)):\n",
    "        img = Image.open(path).convert(\"RGB\").resize((dimension, dimension))\n",
    "        out[\"train\"][i,...] = np.asarray(img)\n",
    "    for i, path in tqdm.tqdm(enumerate(validation_data_files)):\n",
    "        img = Image.open(path).convert(\"RGB\").resize((dimension, dimension))\n",
    "        out[\"validation\"][i,...] = np.asarray(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scandir_iterator = os.scandir(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i,item in  enumerate(scandir_iterator):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
